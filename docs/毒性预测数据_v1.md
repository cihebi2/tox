# 毒性预测数据 v1：来源标准化、标签统一与去重汇总

更新时间：2026-01-15 16:43:26 +0800

本文档把多个“毒性预测”项目中**可直接使用**的数据做了统一整理：为每条序列补齐**标准来源（可追溯到具体文件与记录）**与**统一标签定义**，并在全局范围做**去重与冲突样本隔离**，最终将可复用的 v1 数据集落盘到本仓库 `data/` 目录。

> 标签统一约定：`label=1` 表示 **toxic**，`label=0` 表示 **non-toxic**。

---

## 1. 数据源清单（标准化 dataset_id）

所有数据源都被赋予一个稳定的 `dataset_id`，并将“来源文件路径 + 标签抽取规则”写入：

- `data/toxicity_data_v1/sources_catalog.csv`

本次纳入两类数据：

- **peptide-level（主线，后续训练/检索/改造建议优先用）**
  - ToxGIN（CSV：序列+标签）
  - ToxiPep（FASTA：header 前缀 pos/neg）
  - ToxMSRC（FASTA：header 后缀 |0/|1）
  - HyPepTox-Fuse（FASTA：按文件名 pos/neg）
- **protein-level（单独存放，不与 peptide 合并）**
  - ToxDL2（FASTA：header 末 token 为 0/1）

---

## 2. 标签抽取与标准化规则（“标准来源 + 标签”）

### 2.1 序列标准化（去重使用的 key）

对所有输入序列做统一规范化，用规范化后的序列作为“去重 key”：

1) 去掉空白字符、换行，统一为大写；
2) 去掉常见非字母符号（如 `-`、`*`）；
3) 将 `{U,Z,O,B,J}` 映射为 `X`（unknown），并限制字母表为 `20AA + X`；
4) 不满足字母表的样本会被丢弃并计数（本次数据源中未出现 `X`，也未发生丢弃）。

### 2.2 各来源的标签抽取规则（可追溯）

每条样本都会带上以下字段，保证来源可追溯：

- `source_project`：项目名（如 `ToxGIN`）
- `source_dataset`：标准化 `dataset_id`（如 `toxgin_train`）
- `source_split`：原始 split（train/test/independent 等）
- `source_file`：原始文件的绝对路径
- `source_id`：原始记录标识（CSV 行号 / FASTA header ID）

标签抽取规则按项目如下：

- **ToxGIN**：读取 CSV 列 `label`（0/1），序列列 `sequence`
  - `/root/private_data/dd_model/ToxGIN/train_sequence.csv`（`toxgin_train`）
  - `/root/private_data/dd_model/ToxGIN/test_sequence.csv`（`toxgin_test`）
- **ToxiPep**：读取 FASTA；header 以 `>pos` 开头记为 1，以 `>neg` 开头记为 0
  - `/root/private_data/dd_model/ToxiPep/Dataset/.../*.txt`（`toxipep_*`）
- **ToxMSRC**：读取 FASTA；header 末尾 `|1` 记为 1，`|0` 记为 0
  - `/root/private_data/dd_model/ToxMSRC/Raw data/*.fasta`（`toxmsrc_*`）
- **HyPepTox-Fuse**：读取 FASTA；按文件名赋 label（`*_pos.fa`=>1，`*_neg.fa`=>0）
  - `/root/private_data/dd_model/toxin/HyPepTox-Fuse/raw_dataset/*.fa`（`hypeptoxfuse_*`）
- **ToxDL2（protein-level）**：读取 FASTA；header 最后一个 token 为 `0/1`
  - `/root/private_data/dd_model/ToxDL2/data/protein_sequences/*.fasta`（`toxdl2_*`）

---

## 3. 去重策略与“冲突样本”处理

### 3.1 去重策略

- 对所有样本使用“规范化后的序列”作为唯一 key；
- 同一序列来自多个来源/多个 split 时，不做重复保留：合并其 `sources` 作为 provenance（见下）。

### 3.2 冲突样本（同序列不同标签）

当同一条序列在不同来源出现**标签不一致**（同时出现 `0` 与 `1`）时：

- 该序列被标记为 **conflict**，单独写入 `dedup_conflicts.csv`；
- 不进入最终可训练的 `dedup_resolved.csv`（避免把“数据源定义差异/噪声”硬塞进监督信号）。

---

## 4. 统计汇总（v1 构建结果）

> 统计来自 `data/toxicity_data_v1/peptide/stats.json` 与 `data/toxicity_data_v1/protein/stats.json`。

### 4.1 peptide-level（跨源合并）

**原始来源规模（去重前，均为 kept=total）**

| dataset_id | split | n | label=0 | label=1 |
|---|---:|---:|---:|---:|
| toxgin_train | train | 3864 | 1932 | 1932 |
| toxgin_test | test | 564 | 282 | 282 |
| toxipep_0.9_train | train | 7056 | 3528 | 3528 |
| toxipep_0.9_test | test | 1766 | 883 | 883 |
| toxipep_0.8_train | train | 5544 | 2772 | 2772 |
| toxipep_0.8_test | test | 1388 | 694 | 694 |
| toxipep_independent | independent | 958 | 479 | 479 |
| toxmsrc_train | train | 6387 | 4569 | 1818 |
| toxmsrc_test1 | test1 | 1126 | 806 | 320 |
| toxmsrc_test2 | test2 | 582 | 536 | 46 |
| hypeptoxfuse_train_pos | train_pos | 4414 | 0 | 4414 |
| hypeptoxfuse_train_neg | train_neg | 4414 | 4414 | 0 |
| hypeptoxfuse_test_pos | test_pos | 1104 | 0 | 1104 |
| hypeptoxfuse_test_neg | test_neg | 1104 | 1104 | 0 |

- 原始记录数（合并前）：`40271`
- 全局唯一序列数：`15051`
- 去重后可用（标签一致）：`14675`（label=0: 8184，label=1: 6491）
- 去重后冲突样本：`376`（labels 均为 `[0, 1]`）
- 重复折叠数量：`25220`（同序列多次出现被折叠）
- 跨 dataset_id 重叠的序列数：`10970`（同一序列至少出现在 2 个 dataset_id）

**额外提示（潜在数据泄漏）**

- ToxGIN 的 `train_sequence.csv` 与 `test_sequence.csv` 存在交集：`9` 条序列同时出现在 train 与 test。
  - 如果你要严格评估，需要从 test 中移除这些交集序列，或重新划分 split。

### 4.2 protein-level（ToxDL2，单独存放）

**原始来源规模（去重前，均为 kept=total）**

| dataset_id | split | n | label=0 | label=1 |
|---|---:|---:|---:|---:|
| toxdl2_train | train | 14700 | 9800 | 4900 |
| toxdl2_valid | valid | 931 | 853 | 78 |
| toxdl2_test | test | 1847 | 1735 | 112 |
| toxdl2_independent | independent | 4862 | 4710 | 152 |

- 原始记录数：`22340`
- 全局唯一序列数：`22339`（仅 1 条序列跨 split 重复）
- 去重后可用：`22339`
- 去重后冲突样本：`0`

---

## 5. 落盘文件说明（本仓库 data/）

本次 v1 输出目录：

- `data/toxicity_data_v1/`

其中：

- `data/toxicity_data_v1/sources_catalog.csv`：所有来源 dataset_id 的清单（标准来源、原始路径、标签规则）

**peptide-level**

- `data/toxicity_data_v1/peptide/all_raw.csv`：合并后的原始明细（含每条记录的来源字段）
- `data/toxicity_data_v1/peptide/dedup_resolved.csv`：全局去重后、标签一致的“可用主数据集”
- `data/toxicity_data_v1/peptide/dedup_conflicts.csv`：全局去重后、标签冲突的序列清单
- `data/toxicity_data_v1/peptide/provenance.jsonl`：每条唯一序列的完整来源列表（推荐用于审计/溯源）
- `data/toxicity_data_v1/peptide/stats.json`：可机读统计（per-source + overall）

**protein-level（单独）**

- `data/toxicity_data_v1/protein/all_raw.csv`
- `data/toxicity_data_v1/protein/dedup_resolved.csv`
- `data/toxicity_data_v1/protein/dedup_conflicts.csv`
- `data/toxicity_data_v1/protein/provenance.jsonl`
- `data/toxicity_data_v1/protein/stats.json`

---

## 6. 复现构建流程

本次数据整理由脚本自动生成，可复现：

```bash
python scripts/build_tox_data_v1.py
```

可用 `--out-dir` 指定输出目录（相对本仓库根目录）：

```bash
python scripts/build_tox_data_v1.py --out-dir data/toxicity_data_v1
```

---

## 7. 可用数据分布（peptide：exact-dedup resolved）

统计对象：`data/toxicity_data_v1/peptide/dedup_resolved.csv`（`14675` 条唯一序列，已剔除“同序列不同标签”的冲突样本）。

### 7.1 标签分布

- `label=0`：8184
- `label=1`：6491

### 7.2 序列长度分布（bin）

| length | n |
|---:|---:|
| 1-5 | 51 |
| 6-10 | 718 |
| 11-15 | 2178 |
| 16-20 | 2417 |
| 21-25 | 1668 |
| 26-30 | 2175 |
| 31-35 | 2119 |
| 36-40 | 1312 |
| 41-45 | 1008 |
| 46-50 | 1029 |

### 7.3 跨来源重叠程度（每条序列出现于多少个 dataset_id）

> 由于本次来源中“同一 dataset_id 内重复序列”基本不存在，因此 `n_source_datasets == n_records`。

| n_source_datasets | n |
|---:|---:|
| 1 | 4081 |
| 2 | 2408 |
| 3 | 4267 |
| 4 | 2418 |
| 5 | 1483 |
| 6 | 18 |

### 7.4 各 dataset_id 的“覆盖度”（该 dataset_id 中出现过的唯一序列数）

> 说明：这里统计的是“存在于该 dataset_id 的序列”在 `dedup_resolved` 中的数量（不是原始文件行数）。

| dataset_id | label=0 | label=1 | total |
|---|---:|---:|---:|
| toxipep_0.9_train | 3519 | 3350 | 6869 |
| toxmsrc_train | 4258 | 1818 | 6076 |
| toxipep_0.8_train | 2767 | 2620 | 5387 |
| hypeptoxfuse_train_neg | 4404 | 0 | 4404 |
| hypeptoxfuse_train_pos | 0 | 4129 | 4129 |
| toxgin_train | 1835 | 1932 | 3767 |
| toxipep_0.9_test | 879 | 827 | 1706 |
| toxipep_0.8_test | 689 | 652 | 1341 |
| hypeptoxfuse_test_neg | 1102 | 0 | 1102 |
| toxmsrc_test1 | 755 | 320 | 1075 |
| hypeptoxfuse_test_pos | 0 | 1030 | 1030 |
| toxipep_independent | 478 | 465 | 943 |
| toxmsrc_test2 | 492 | 46 | 538 |
| toxgin_test | 272 | 254 | 526 |

### 7.5 只出现在单一 dataset_id 的序列（n_source_datasets=1）

| dataset_id | n |
|---|---:|
| toxmsrc_train | 1243 |
| hypeptoxfuse_train_pos | 1171 |
| hypeptoxfuse_train_neg | 589 |
| toxipep_independent | 465 |
| hypeptoxfuse_test_pos | 343 |
| hypeptoxfuse_test_neg | 187 |
| toxgin_test | 74 |
| toxgin_train | 9 |

### 7.6 评估注意（潜在数据泄漏）

- ToxGIN 的 `train_sequence.csv` 与 `test_sequence.csv` 有 `9` 条序列交集；若做严格评估，建议移除交集或重划分 split。

---

## 8. 90% 序列相似性去重（CD-HIT，label-aware）

目标：进一步减少“高度相似序列”的冗余（identity ≥ 90%），用于更稳健的训练与评估。

### 8.1 去重定义与工具参数

- 工具：CD-HIT v4.8.1（`cd-hit`）
- 相似性阈值：`-c 0.9`（global identity，按 **短序列长度** 归一化；`-G 1`）
- 覆盖度约束：`-aS 0.9 -aL 0.9`（要求比对覆盖短/长序列各 ≥90%，避免“短片段包含”导致的误聚类）
- 保留短序列：`-l 1`（否则默认会丢弃长度 <10 的序列）
- 运行方式：**按 label 分开聚类（label-aware）**，避免“跨标签合并导致标签丢失/污染”。

复现命令：

```bash
python scripts/dedup_similarity_id90.py --threads 0
```

### 8.2 去重结果（规模变化）

输入（exact-dedup resolved）：

- 总计：14675（label=0: 8184；label=1: 6491）

输出（90% similarity dedup）：

- 总计：12672（label=0: 7615；label=1: 5057）

分标签聚类统计（cluster 数 = 输出序列数）：

| label | input | clusters(output) | removed |
|---:|---:|---:|---:|
| 0 | 8184 | 7615 | 569 |
| 1 | 6491 | 5057 | 1434 |

cluster size 概览（来自 `data/toxicity_data_v1/peptide_id90/stats.json`）：

- label=0：max cluster size = 14（p95=1）
- label=1：max cluster size = 24（p95=2）

### 8.3 去重后长度分布（bin）

统计对象：`data/toxicity_data_v1/peptide_id90/dedup_id90_resolved.csv`

| length | n |
|---:|---:|
| 1-5 | 51 |
| 6-10 | 704 |
| 11-15 | 1797 |
| 16-20 | 2065 |
| 21-25 | 1360 |
| 26-30 | 1842 |
| 31-35 | 1620 |
| 36-40 | 1263 |
| 41-45 | 973 |
| 46-50 | 997 |

### 8.4 输出文件（data/）

输出目录：`data/toxicity_data_v1/peptide_id90/`

- `data/toxicity_data_v1/peptide_id90/dedup_id90_resolved.csv`：90% 去重后的代表序列（含聚类规模与来源 union）
- `data/toxicity_data_v1/peptide_id90/cluster_members.csv`：每条输入序列 → cluster 的映射（可审计/追溯）
- `data/toxicity_data_v1/peptide_id90/dedup_id90_resolved.fa`：代表序列 FASTA（header=cluster_id）
- `data/toxicity_data_v1/peptide_id90/stats.json`：可机读统计
- `data/toxicity_data_v1/peptide_id90/run_manifest.json`：运行参数与工具 banner

---

## 9. 数据划分（train/val/test）

本次先基于 **90% 相似去重后的代表序列集** 进行分层划分（stratified split，按 label 保持比例），并将同一相似簇（cluster）的所有成员映射到同一 split，从而避免相似序列跨 split 泄漏。

划分脚本：

```bash
python scripts/split_tox_data_v1.py
```

### 9.1 划分配置

- 输入（90% 去重代表序列）：`data/toxicity_data_v1/peptide_id90/dedup_id90_resolved.csv`
- 成员映射（exact-dedup 序列 → cluster）：`data/toxicity_data_v1/peptide_id90/cluster_members.csv`
- 随机种子：`69`
- 比例：train/val/test = `0.8/0.1/0.1`
- 输出目录：`data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/`

### 9.2 划分结果（代表序列集，id90 reps）

文件：

- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_id90_train.csv`
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_id90_val.csv`
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_id90_test.csv`

计数（label=0/1）：

| split | total | label=0 | label=1 |
|---|---:|---:|---:|
| train | 10137 | 6092 | 4045 |
| val | 1267 | 761 | 506 |
| test | 1268 | 762 | 506 |

### 9.3 划分结果（exact-dedup 序列集，按 cluster 映射）

> 用途：如果你希望训练时保留更多“去重前”的唯一序列（`14675`），但仍保持 90% 相似簇不跨 split，可用此版本。

文件：

- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_exact_train.csv`
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_exact_val.csv`
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_exact_test.csv`
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/peptide_exact_by_cluster.csv`（全量带 split）

计数（label=0/1）：

| split | total | label=0 | label=1 |
|---|---:|---:|---:|
| train | 11709 | 6551 | 5158 |
| val | 1512 | 828 | 684 |
| test | 1454 | 805 | 649 |

### 9.4 审计文件

- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/clusters_split.csv`：cluster_id → split（用于审计相似簇是否跨 split）
- `data/toxicity_data_v1/splits/peptide_id90_seed69_80_10_10/split_stats.json`：可机读配置与统计（含时间戳）

---

## 10. 可用创新点（面向后续“多端点毒性”数据收集与评估）

更新时间：2026-01-15 22:30:30 +0800

你后续会收集“多端点毒性”数据。结合当前已调研的最新工作（`docs/毒性预测论文.md`）与本仓库的数据规范（来源可追溯、标签统一、去冗余与固定切分），下面这些创新点**可以直接复用**，并且对数据字段/版本管理有明确要求：

1) **时间外推评估（Time-split / post-year holdout）**（参考 ToxDL2 的 pre/post‑2022 评估范式）  
   - 数据侧要求：新增/外部数据建议记录 `release_date/collection_date`（至少到年），并保留“可审计的时间分界线”。  
   - 落地建议：每个 endpoint 都应提供 `in-time test` + `out-of-time test`（或至少在总任务层面提供一次时间外推集）。

2) **不平衡场景的评价与训练策略**（参考 ToxDL2/pepADMET 的真实分布）  
   - 数据侧要求：保留原始分布与采样规则（负样本如何构建/过滤），并在 `sources_catalog.csv` 或 split manifest 中记录采样策略与随机种子。  
   - 指标侧要求：除 AUROC 外，必须记录 **AUPRC/PR curve** 与 **BACC（balanced accuracy）**；在极端不平衡外部集上优先看 PR/BACC/MCC。

3) **多端点/层级毒性（Multi-endpoint / hierarchical toxicity）**（参考 pepADMET、ToxPre-2L）  
   - 数据侧要求：为每条样本增加 `endpoint_id`（如 hemolysis/cytotoxicity/neurotoxicity…）、`assay_type`、`measurement`（值/单位/阈值）与 `label_rule`（如何从测量值映射为标签）。  
   - 落地建议：先把多端点做成“多任务二分类/回归”的统一 schema（同一序列可有多个 endpoint 记录），再决定是否做层级分类（机制/类别）。

4) **更严格的“同源/相似泄漏”控制**（参考 ToxiPep 的 CD‑HIT 0.9/0.8 双阈值）  
   - 数据侧要求：在每个 endpoint 内分别做去冗余（如 CD‑HIT 0.9/0.8），并把 cluster 映射与代表序列落盘，确保审计“相似簇不跨 split”。  
   - 落地建议：对 protein-level 任务尤其重要；可用 0.9 做主线复现，0.8 作为更严格泛化评估。

5) **证据检索（Retrieval as Evidence）与可核验引用**  
   - 数据侧要求：对外部/实验数据尽可能记录 `source_db`、`accession/id`、`doi/url`、实验条件摘要；保证“预测结论”可回溯到原始证据条目。  
   - 落地建议：证据库与训练集分离管理（训练只用 train split；检索展示可包括 external，但需标明来源与是否参与训练）。

6) **可解释性（IG/ISM/SHAP）需要的最小元数据**  
   - 数据侧要求：对 protein-level 若希望把解释对齐到 domain/motif（参考 ToxDL2），建议保留 domain 注释字段（如 InterPro/Pfam ID、区间），便于把 saliency 映射到功能片段。  
   - 落地建议：对多端点任务，解释应按 endpoint 输出（不同毒性端点可能对应不同 motif/区域）。

7) **可复现与版本审计（对论文/产品都关键）**  
   - 数据侧要求：固定 split、落盘 manifest（时间戳/参数/hash），并保存每次训练的预测输出（含概率与不确定性）。  
   - 落地建议：后续新增外部数据时不要“覆盖 v1”，而是新建 `toxicity_data_v2/` 并保留 v1 可复现链路。
